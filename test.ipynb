{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978becba-1e39-4fa2-953c-36a58af375ea",
   "metadata": {},
   "source": [
    "# Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6137e875-d61a-41c9-8e7c-e6af7d94c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "from utils.config_parser import load_config\n",
    "cfg = load_config(\"config/example_moe_config.yaml\")\n",
    "print(cfg.model.moe_layers)   # -> [2, 4, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea129ff-c810-40f1-b198-2fdb698bd3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84, 2]) tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import build_dataloader\n",
    "dl = build_dataloader(\n",
    "        root=\"data/USPTO_480k\",\n",
    "        split=\"train\",\n",
    "        batch_size=2,\n",
    "        vocab_file=\"data/USPTO_480k/vocab_smiles.txt\"\n",
    ")\n",
    "\n",
    "batch = next(iter(dl))\n",
    "print(batch[\"src_tokens\"].shape, batch[\"decoder_in\"][0][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44638b-f482-4dce-911b-da4e35f7888e",
   "metadata": {},
   "source": [
    "# Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99941535-1e60-45b8-b0d7-9adacadcdaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "from models.transformer_layers import EncoderLayer, DecoderLayer, subsequent_mask\n",
    "import torch\n",
    "\n",
    "enc = EncoderLayer(d_model=512, n_head=8, d_ff=2048, dropout=0.1)\n",
    "x = torch.randn(20, 4, 512)          # (L=20, B=4, D=512)\n",
    "pad_mask = torch.zeros(4, 20, dtype=torch.bool)\n",
    "y = enc(x, pad_mask)                 # forward pass\n",
    "print(y.shape)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb0002-8a14-4771-9668-33a4dab75bf3",
   "metadata": {},
   "source": [
    "# Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812b43b3-f9b5-48c7-8200-f6300e6ecb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 256])\n",
      "aux_loss = 0.2534775137901306\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.moe_layer import MoEFFN\n",
    "\n",
    "ffn = MoEFFN(d_model=256, d_ff=1024, n_experts=4)\n",
    "x = torch.randn(10, 3, 256)           # (L=10, B=3, D=256)\n",
    "y = ffn(x)\n",
    "print(y.shape)                        # torch.Size([10, 3, 256])\n",
    "print(\"aux_loss =\", ffn.aux_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5159896-1345-4c08-b4de-4acd50fdbc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60423c98-1576-4163-bcd1-cfae19693552",
   "metadata": {},
   "source": [
    "# Batch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f886d4-1be7-4834-9c35-aa47da17ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([30, 4, 300])\n",
      "aux_loss 1.8701659440994263\n"
     ]
    }
   ],
   "source": [
    "import torch, pickle\n",
    "from utils.config_parser import load_config\n",
    "from models import build_model          # imported from __init__\n",
    "\n",
    "cfg = load_config(\"config/example_moe_config.yaml\")\n",
    "\n",
    "# toy vocab size\n",
    "vocab_size = 300\n",
    "\n",
    "model = build_model(cfg, vocab_size)\n",
    "model.eval()\n",
    "\n",
    "B = 4\n",
    "src = torch.randint(5, vocab_size, (25, B))\n",
    "tgt_in = torch.randint(5, vocab_size, (30, B))\n",
    "src_mask = src.eq(0).t()\n",
    "tgt_mask = tgt_in.eq(0).t()\n",
    "\n",
    "logits, aux = model(src, tgt_in, src_mask, tgt_mask)\n",
    "print(\"logits\", logits.shape)           # (L_tgt, B, vocab)\n",
    "print(\"aux_loss\", aux.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46240440-be7b-4043-b493-a366741b729c",
   "metadata": {},
   "source": [
    "# Batch 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69dc735d-4a4e-4d28-b3f9-358f5a78244e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "python training/train.py config/example_moe_config.yaml --debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93f4d737-8993-40a6-8eba-f18901f2b253",
   "metadata": {},
   "source": [
    "epoch,split,loss,tok_acc,seq_acc,aux_loss\n",
    "1,train,3.4567,0.8912,0.1420,0.0041\n",
    "1,val,  3.3210,0.8950,0.1500,0.0040\n",
    "...|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2609882-d4a1-40a2-921e-1536ba1ccf64",
   "metadata": {},
   "source": [
    "# Batch 6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d08fb2b7-1d4a-4e96-86ee-a6c33eb0fd71",
   "metadata": {},
   "source": [
    "python evaluation/evaluate.py \\\n",
    "       --config config/example_moe_config.yaml \\\n",
    "       --checkpoint checkpoints/model_epoch5.pt \\\n",
    "       --split val \\\n",
    "       --batch_size 32\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0abeec6d-6be0-488d-8071-d9caf450d6ff",
   "metadata": {},
   "source": [
    "[val] Token‑Acc=0.8954 Seq‑Acc=0.1552 Aux‑Loss=0.0038\n",
    "Results appended to checkpoints/eval_results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3fccb-361a-4d67-8030-5f1f894ef1d4",
   "metadata": {},
   "source": [
    "# Batch 7"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fa95497-173b-4ec9-81c2-e531e9f5ad25",
   "metadata": {},
   "source": [
    "python preprocessing/preprocess_smiles.py \\\n",
    "       --input uspto_raw.txt \\\n",
    "       --output_dir preprocessed/USPTO_480k_smiles \\\n",
    "       --representation smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d81be8-0c19-4b80-992e-0d948ee5b575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78292736-f6de-4a55-8692-d3fb5247493d",
   "metadata": {},
   "source": [
    "# Batch 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882f0c3-0e1e-47fe-9909-729cdd29c1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
