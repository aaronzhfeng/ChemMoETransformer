{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3b54e1-504e-486e-8a5a-8c6df80fd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dadd03-99f1-487f-9a2c-c3c94118298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote vocab: data/USPTO_480k/vocab_smiles.txt size = 299\n"
     ]
    }
   ],
   "source": [
    "# 1) collect all distinct SMILES tokens\n",
    "tok_counter = Counter()\n",
    "for split in (\"train\",\"val\",\"test\"):\n",
    "    for f in (Path(\"data/USPTO_480k\")/f\"src-{split}.txt\",\n",
    "              Path(\"data/USPTO_480k\")/f\"tgt-{split}.txt\"):\n",
    "        with open(f) as fh:\n",
    "            for line in fh:\n",
    "                tok_counter.update(line.strip().split())\n",
    "\n",
    "# 2) write vocab with special tokens first\n",
    "out = Path(\"data/USPTO_480k/vocab_smiles.txt\")\n",
    "with open(out, \"w\") as vf:\n",
    "    for tok in [\"<PAD>\",\"<UNK>\",\"<BOS>\",\"<EOS>\"]:\n",
    "        vf.write(tok+\"\\n\")\n",
    "    for tok in sorted(tok_counter):\n",
    "        vf.write(tok+\"\\n\")\n",
    "print(\"Wrote vocab:\", out, \"size =\", len(tok_counter)+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d03a9d-add0-441f-b5e6-556678216e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: torch.Size([73, 2]) dec_in first row: tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import build_dataloader\n",
    "dl = build_dataloader(\n",
    "    root=\"data/USPTO_480k\",\n",
    "    split=\"train\",\n",
    "    batch_size=2,\n",
    "    vocab_file=\"data/USPTO_480k/vocab_smiles.txt\",\n",
    "    num_workers=0\n",
    ")\n",
    "batch = next(iter(dl))\n",
    "print(\"src:\", batch[\"src_tokens\"].shape,\n",
    "      \"dec_in first row:\", batch[\"decoder_in\"][0][:8])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9acafafc-6a2b-4858-add8-334fc3f6905a",
   "metadata": {},
   "source": [
    "python -m training.train \\\n",
    "  config/example_moe_config.yaml \\\n",
    "  --debug"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a680664-597a-4475-9303-bae7b3bdcf8c",
   "metadata": {},
   "source": [
    "python -m training.train config/example_moe_config.yaml\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
